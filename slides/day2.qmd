---
title: "NORSAR ML Workshop"
subtitle: "Day 2 -- Wednesday"
author: "steffen.maeland@norsar.no"
date: "September 18, 2025"
format:
  revealjs:
    auto-stretch: false
    auto-play-media: true
---


## _Deep_ learning

<!-- First: generalised deep learning -->
:::{style="padding-top: 10px;"}
:::

The point of deep learning is to sequentially **learn better feature representations**, and use these to solve a task.

:::{style="padding-top: 15px;"}
:::

:::{.columns}
:::{.column width="13%"}
[_insufficient:_]{style="color: #C62828;"}
<br>
<br>
[_good:_]{style="color: #F57C00;"}
<br>
<br>
<br>
[_better:_]{style="color: #2E7D32;"}
:::

:::{.column width="5%"}
:::

:::{.column width="7%"}
data
<br>
<br>
data
<br>
<br>
<br>
data
:::

:::{.column width="5%"}
$\rightarrow$
<br>
<br>
$\rightarrow$
<br>
<br>
<br>
$\rightarrow$
:::

:::{.column width="20%"}
prediction
<br>
<br>
representation<br>
[_(e.g. crosscorr)_]{.color-text-muted}
<br>
<br>
representation
[_(e.g. crosscorr)_]{.color-text-muted}
:::

:::{.column width="5%"}
<br>
<br>

$\rightarrow$
<br>
<br>
<br>
$\rightarrow$
:::

:::{.column width="20%"}
<br>
<br>

prediction
<br>
<br>
<br>
representation
[_(e.g. crosscorr)_]{.color-text-muted}
:::

:::{.column width="5%"}
<br>
<br>

&nbsp;
<br>
<br>
<br>

$\rightarrow$
:::

:::{.column width="20%"}
<br>
<br>

&nbsp;
<br>
<br>
<br>

prediction
:::
:::

:::{style="padding-top: 10px;"}
:::

:::{.fragment}
Since neural networks are [_universal function approximators_]{.pink}, they can model arbitrarily complex relationships. The cost of doing so, is that we need a [lot of data]{.purple}.
:::



## Crosscorrelation

Crosscorrelation of two real-valued functions $f$ and $g$ is defined as

$$
(f \star g)(\tau) = \int_{-\infty}^{\infty} f(t)g(t + \tau)
$$

For discrete signals the operation is computationally simple since $\int \rightarrow \sum$ and we just need to multiply and sum. 

:::{style="padding-top: 10px;"}
:::

![](https://upload.wikimedia.org/wikipedia/commons/7/71/Cross_correlation_animation.gif)



## Convolutions recap

![](figures/conv1d-0.png)

## Convolutions recap

![](figures/conv1d-1.png)

## Convolutions recap

![](figures/conv1d-2.png)

## Convolutions recap

![](figures/conv1d-3.png)

## Convolutions recap

![](figures/conv1d-4.png)

## Convolutions recap

![](figures/conv1d-last.png)


## Crosscorrelation appreciation slide

:::{.absolute top="15%" left="20%" width="550px"}
![](figures/box-crosscorrelation.png){fig-align="center"style="margin-top: 0px;"}
:::

:::{.fragment .fade-out .rectangle .absolute top="40%" left="20%" width="650px" height="100px" style="background-color: #fff; border: 1px;"}
:::

:::{style="padding-top: 40%;"}
:::

**Note:**  Time-reversing $f$ in the definition of crosscorrelation yields the [_**convolution**_]{.pink} operation.

In ML we got the terms mixed up and only talk about [_convolution_]{.pink}, even though we do crosscorrelation. 


## Some more terminology

- Layer: A slice of the model where an internal representation is computed

:::{.columns style="text-align: center;"}
:::{.column width="5%"}
:::

:::{.column width="20%"}
data<br>([_input layer_]{.teal})
:::

:::{.column width="5%"}
$\rightarrow$
:::

:::{.column width="20%"}
representation<br>([*hidden layer 1*]{.orange})
:::

:::{.column width="5%"}
$\rightarrow$
:::

:::{.column width="20%"}
representation<br>([*hidden layer 2*]{.orange})
:::

:::{.column width="5%"}
$\rightarrow$
:::

:::{.column width="20%"}
prediction<br>([*output layer*]{.teal})
:::
:::

:::{style="padding-top: 10px;"}
:::




## Some deep learning frameworks 

::::{.r-stack}

:::{.absolute left="30%" top="20%" width="400px"}
[![](https://keras.io/img/logo.png)](https://keras.io/)
:::

:::{.absolute left="0%" bottom="20%" width="250px"}
[![](https://upload.wikimedia.org/wikipedia/commons/thumb/a/ab/TensorFlow_logo.svg/330px-TensorFlow_logo.svg.png)](https://www.tensorflow.org/)
:::

:::{.absolute left="30%" bottom="25%" width="150px"}
[![](https://upload.wikimedia.org/wikipedia/commons/thumb/8/86/Google_JAX_logo.svg/640px-Google_JAX_logo.svg.png)](https://jax.readthedocs.io/en/latest/)
:::

:::{.absolute left="55%" bottom="25%" width="250px"}
[![](https://upload.wikimedia.org/wikipedia/commons/9/96/Pytorch_logo.png)](https://pytorch.org/)
:::

:::{.absolute left="15%" bottom="0%" width="150px"}
[![](https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/Scikit_learn_logo_small.svg/640px-Scikit_learn_logo_small.svg.png)](https://scikit-learn.org/stable/)
:::

:::{.absolute left="45%" bottom="0%" width="170px"}
[![](https://upload.wikimedia.org/wikipedia/commons/thumb/3/31/NumPy_logo_2020.svg/640px-NumPy_logo_2020.svg.png)](https://numpy.org/doc/stable/)
:::


::::

:::{.absolute right="0%" top="25%"}
[High-level]{.blue} <br> _(optional)_
:::

:::{.absolute right="0%" bottom="30%"}
[Compute]{.blue} <br> _(choose one)_
:::

:::{.absolute right="0%" bottom="7%"}
[Supporting]{.blue} <br> _(useful)_
:::


## Interlude: Programming ğŸ‘©ğŸ¼â€ğŸ’»{.center background-color="#FBE9E7"}



## NumPy: _Numerical Python_

:::{.columns}
:::{.column width="60%"}
Most [_(all?)_]{.color-text-muted} scientific or data-driven Python projects rely on NumPy.

The different deep learning libraries implement the same concepts, so if we know NumPy, the transition to `<new flashy DL libraryâœ¨>` is easy.

:::{style="padding-top: 40px;"}
:::

:::{style="background-color: #E0F2F1; padding: 20px;" .img-shadow}
Core concept: [**Vectorisation**]{.teal}

Performing efficent operations on all data at once, without writing explicit loops
:::

:::
:::


:::{.absolute right="-5%" top="35%" width="370px"}
[![](https://upload.wikimedia.org/wikipedia/commons/thumb/3/31/NumPy_logo_2020.svg/640px-NumPy_logo_2020.svg.png)](https://numpy.org/doc/stable/)
:::



## {background-iframe="https://numpy.org/learn/" background-interactive="true" data-menu-title="Numpy docs"}

## NumPy arrays

At the core of NumPy is the `array`, which supports vectorised operations.

>_Example:_ Given a list of numbers, make a new list, where all the elements are multiplied by 2.

:::{.columns}

:::{.column width="50%"}

[Vanilla python:]{ style="margin-top=0px"}

```{.python}
>>> a = [1,2,3]; b = []
>>> for elem in a:
>>>   b.append(elem * 2)
b
[2, 4, 6]
```
:::

:::{.column width="50%"}
:::{.fragment}
Numpy:
```{.python code-line-numbers="1-5|3" }
>>> import numpy as np
>>> a = np.array([1,2,3])
>>> b = a * 2
>>> b
array([2 4 6])
```
:::
:::
:::

:::{.fragment}
Arrays can have any number of dimensions -- e.g. a 2D matrix is written
```{.python code-line-numbers="1|1,2-4|1,5-6"}
>>> a = np.array([[1,2,3],[4,5,6]])
>>> print(a)
[[1 2 3]
 [4 5 6]]
>>> a.shape
(2, 3)
```
:::


## NumPy arrays: Selecting data

In normal python, elements are _sliced_ from a list using `[start : stop]`:
```{.python code-line-numbers="false"}
>>> a = [0, 1, 2, 3, 4]
>>> a[2:4]                  # (remember zero-based indexing)
[2, 3]    
>>> a[:]                    # no start or stop -> select everything
[0, 1, 2, 3, 4]
```

:::{.fragment}
NumPy extends this to any number of dimensions, separated by "`,`":
```{.python code-line-numbers="false"}
>>> a = np.arange(1,10).reshape(3,3)
>>> a
array([[1, 2, 3],
       [4, 5, 6],
       [7, 8, 9]])
```
:::

:::{.columns}

:::{.column width="33%"}
:::{.fragment}
Select single element:
```{.python code-line-numbers="false"}
>>> a[1, 1]
5
```
:::
:::

:::{.column width="33%"}
:::{.fragment}
Select row:
```{.python code-line-numbers="false"}
>>> a[1, :]
array([4, 5, 6])
```
:::
:::

:::{.column width="33%"}
:::{.fragment}
Select column:
```{.python code-line-numbers="false"}
>>> a[:, 1]
array([2, 5, 8])
```
:::
:::

:::


## NumPy arrays: _Broadcasting_

Operations on arrays are typically done [element-by-element]{.color-teal}.

:::{.columns}
:::{.column width="50%"}
```{.python code-line-numbers="false"}
>>> a = np.array([1,2,3])
>>> np.power(a, 2)
array([1, 4, 9])
```
:::

:::{.column width="50%"}
:::{.fragment}
```{.python  code-line-numbers="false"}
>>> b = np.array([4,5,6])
>>> a * b
array([ 4, 10, 18])
```
:::
:::
:::

:::{.fragment}
In cases the shapes of two arrays don't match, numpy will try to [_make_]{.red} them match<br>(aka _broadcasting_):

```{.python code-line-numbers="1-3|1-6"}
# I type this
>>> a * 2
array([2, 4, 6])
# ...and numpy does this:
>>> a * np.array([2, 2, 2])
array([2, 4, 6])
```
:::

:::{.fragment}
![Numpy [docs](https://numpy.org/doc/stable/user/basics.broadcasting.html)](https://numpy.org/doc/stable/_images/broadcasting_1.png){width="40%" style="text-align: center;"}
:::


## Shapes




## Low-level TensorFlow

Usually we don't need to get involved with TensorFlow. But in case:

Most things work like NumPy, but with the benefit of GPU support and JIT compilation.

The core object is the [`Tensor`](https://www.tensorflow.org/api_docs/python/tf/Tensor), which is basically a multidimensional array.  

:::{.fragment}
NumPy

```{.python code-line-numbers="1,2|"}
>>> import numpy as np
>>> x = np.array([[1,2,3], [4,5,6]], dtype=np.float32)
>>> print(x)
[[1. 2. 3.]
 [4. 5. 6.]]

```
:::

:::{.fragment}
TensorFlow

```{.python code-line-numbers="1,2|"}
>>> import tensorflow as tf
>>> x = tf.constant([[1,2,3], [4,5,6]], dtype=tf.float32)
>>> print(x)
tf.Tensor(
[[1. 2. 3.]
 [4. 5. 6.]], shape=(2, 3), dtype=float32)
```
:::


## Building neural networks {.center background-color="#FCE4EC"}

<!-- :::{.absolute right="0%" top="0%" width="300px"} -->
[![](https://keras.io/img/logo.png){width="180px"}](https://keras.io/)
<!-- ::: -->





## My first convolutional network ğŸ¦„

Yesterday we pieced together a [**convnet**]{.color-indigo} using Keras' [sequential model API](https://keras.io/api/models/sequential/):


:::{style="padding-top:30px;"}
:::

```{.python code-line-numbers="|1|3|5,6|8,9|11|13|15|"}
model = keras.Sequential(
    [
        keras.Input(shape=(waveforms.shape[1], waveforms.shape[2])),
        
        keras.layers.Conv1D(filters=16, kernel_size=3, activation='relu'),
        keras.layers.MaxPooling1D(2),
        
        keras.layers.Conv1D(filters=16, kernel_size=3, activation='relu'),
        keras.layers.MaxPooling1D(2),
        
        keras.layers.Conv1D(filters=16, kernel_size=3, activation='relu'),
        
        keras.layers.GlobalMaxPooling1D(),
        
        keras.layers.Dense(1, activation='sigmoid')
    ]
)

```

## Pattern hierarchies

Remember the cat:

![](figures/chollet-cat.png){fig-align="center" width="60%"}



## Keras

The [Keras](https://keras.io/) framework contains all the high-level components we need to construct and train a neural network:

- `keras.layers`: Different types of layers and activation functions
- `keras.callbacks`: Monitor, modify or stop the training process
- `keras.optimizers`: Optimisation algorithms
- `keras.metrics`: Performance metrics
- `keras.losses`: Loss functions 
- `keras.datasets`: Small datasets for testing
- `keras.applications`: Pre-trained networks for different tasks

:::{.r-stack}

:::{.absolute bottom="0%" right="0%" width="200px"}
![](https://keras.io/img/logo.png)
:::

:::


## Exercise number 3 {.center background-color="#FBE9E7"}

:::{style="padding-top:30px;"}
:::

_Building a phase picker_

Open in [Colab](https://colab.research.google.com/github/smaeland/norsar-ml-workshop/blob/main/3_phase_picker.ipynb)
or [download](https://github.com/smaeland/norsar-ml-workshop/blob/main/3_phase_picker.ipynb)




<!--------------------------------------------------------------------------------------------------->

## Pretrained networks

seisbench


## Current seismology SOTA 

What does the SOTA model look like

##

Tina: Use cases besides phase picking, avalanche detection, etc

-> transfer learning


## LOL

Our _short_ templates can be "re-used" to detect similar but distinct patterns

However, most interesting patterns are considerably longer than the templates.

-> Want a way to compose small patterns into larger ones



<!-- Then: time series deep learning  --> 


## Training



## Exercise 1

First: Repeat phase picksing from yesterday








## Enter the _convolution operation_

The foundation for modern computer vision [_(plus lots of other things!)_]{.color-grey}<br>
is [**convolution**]{.color-purple}:

an operation that takes in two functions and returns a new function

:::{style="padding-top: 40px;"}
:::

::::{.columns}
:::{.column width="50%}
$$
f \ast g \equiv \int_{-\infty}^{\infty} f(\tau) g(t-\tau) d\tau
$$
:::

:::{.column width="50%}
:::{.fragment}
![](https://upload.wikimedia.org/wikipedia/commons/6/6a/Convolution_of_box_signal_with_itself2.gif)
:::
:::

::::



## Enter the _convolution operation_

The foundation for modern computer vision [_(plus lots of other things!)_]{.color-grey}<br>
is [**convolution**]{.color-purple}:

an operation that takes in two functions and returns a new function

:::{style="padding-top: 40px;"}
:::

::::{.columns}
:::{.column width="50%}
$$
f \ast g \equiv \int_{-\infty}^{\infty} f(\tau) g(t-\tau) d\tau
$$
:::

:::{.column width="50%}
![](https://upload.wikimedia.org/wikipedia/commons/b/b9/Convolution_of_spiky_function_with_box2.gif)
:::

::::

In practice, convolution is a way to **recognise and localise patterns** in data


## Discrete convolution

Convolution is a lot easier with discrete data such as images, because:

 - the integral becomes a [sum]{.color-pink-dark}
 - the first function is our [image]{.color-pink-dark}
 - the second function is our [_**kernel**_]{.color-pink-dark} or [_**filter**_]{.color-pink-dark}, which tries to find patterns in the image.


:::{.fragment}
![](https://upload.wikimedia.org/wikipedia/commons/7/71/Cross_correlation_animation.gif)
:::

## Convolutions detour

If the take the convolution operation

$$
\small
f \ast g \equiv \int_{-\infty}^{\infty} f(\tau) g(t-\tau) d\tau
$$

but reverse one of the functions ($\small f(t) \to f(-t)$), we get the similar operation called _cross-correlation_:

:::{style="margin-top: -30px;"}
$$
\small
f \star g \equiv f(-t) \ast g(t)
$$
:::

![](figures/box-crosscorrelation.png){fig-align="center" width="550px" style="margin-top: 0px;"}


:::{.fragment .fade-out .rectangle .absolute bottom="-20px" left="200px" width="650px" height="100px" style="background-color: #fff; border: 0px;"}
:::

## Break {.center background-color="#23e323"}


## Seismology tasks solved with ML / current SOTA


## Exercise 2

Train an ML pick detector


## Post-exercise









## Augmentation



Move to day 2



## DAY 2


## Recap from day 1



## The more advanced stuff

Deep learning components

## Libraries for machine learning


## Python libraries

:::{style="margin-top: 10%"}
:::


:::{.columns }
:::{.column width="45%"}
![https://numpy.org/](figures/numpy-logo.png){width="55%" style="text-align: center;"}

`numpy` provides fast manipulation of large arrays and matrices
:::

:::{.column width="5%"}
:::

:::{.column width="45%"}
![https://scikit-learn.org/](figures/sklearn-logo.png){width="45%" style="text-align: center;"}

`scikit-learn` has a big selection of machine learning models and functions for data processing and evaluation
:::

:::


## Shapes

Broadcasting_ works like in NumPy: 

```{.python}
>>> x = tf.constant([1,2,3], dtype=tf.float32)
>>> x + 1
<tf.Tensor: shape=(3,), dtype=float32, numpy=array([2., 3., 4.], dtype=float32)>
```

Same for _shapes_: 

:::{.r-stack}

![](figures/shapes1.png){width="80%"}

:::{.fragment}
![](figures/shapes2.png){width="80%"}
:::

:::


## Low-level TensorFlow

Usually we don't need to get involved with TensorFlow. But in case:

Most things work like NumPy, but with the benefit of GPU support and JIT compilation.

The core object is the [`Tensor`](https://www.tensorflow.org/api_docs/python/tf/Tensor), which is basically a multidimensional array.  

:::{.fragment}
NumPy

```{.python code-line-numbers="1,2|"}
>>> import numpy as np
>>> x = np.array([[1,2,3], [4,5,6]], dtype=np.float32)
>>> print(x)
[[1. 2. 3.]
 [4. 5. 6.]]

```
:::

:::{.fragment}
TensorFlow

```{.python code-line-numbers="1,2|"}
>>> import tensorflow as tf
>>> x = tf.constant([[1,2,3], [4,5,6]], dtype=tf.float32)
>>> print(x)
tf.Tensor(
[[1. 2. 3.]
 [4. 5. 6.]], shape=(2, 3), dtype=float32)
```
:::


## My first convolutional network âœ¨

```{.python}
convnet.summary()
```

```
Model: "sequential_1"

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)                         â”ƒ Output Shape                â”ƒ         Param # â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ conv2d (Conv2D)                      â”‚ (None, 26, 26, 32)          â”‚             320 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d (MaxPooling2D)         â”‚ (None, 13, 13, 32)          â”‚               0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)                    â”‚ (None, 11, 11, 32)          â”‚           9,248 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1 (MaxPooling2D)       â”‚ (None, 5, 5, 32)            â”‚               0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ flatten_1 (Flatten)                  â”‚ (None, 800)                 â”‚               0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout (Dropout)                    â”‚ (None, 800)                 â”‚               0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_3 (Dense)                      â”‚ (None, 10)                  â”‚           8,010 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

 Total params: 17,578 (68.66 KB)

 Trainable params: 17,578 (68.66 KB)

 Non-trainable params: 0 (0.00 B)
```

## My first convolutional network âœ¨

Configure the training objective and strategy:

```{.python}
convnet.compile(
  loss="categorical_crossentropy",
  optimizer="adam",
  metrics=["accuracy"]
)
```
(again, more details next week)

Start training!
```{.python}
convnet.fit(
  X_train,
  y_train,
  batch_size=128,
  epochs=15,
  validation_split=0.1
)
```





## Putting together an improved network



## Pretrained models

## Exercise: Unsupervised learning with pretrained image models?




## SOTA research


https://www.nature.com/articles/s41467-020-17591-w/figures/3

![](https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41467-020-17591-w/MediaObjects/41467_2020_17591_Fig3_HTML.png?as=webp)


## NORSAR developments


## Future directions at NORSAR

Arrays 

## Hackathon
