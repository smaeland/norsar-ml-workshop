---
title: "NORSAR ML Workshop"
subtitle: "Day 2 -- Wednesday"
author: "steffen.maeland@norsar.no"
date: "September 18, 2025"
format:
  revealjs:
    auto-stretch: false
    auto-play-media: true
---


## _Deep_ learning

<!-- First: generalised deep learning -->
:::{style="padding-top: 10px;"}
:::

The point of deep learning is to sequentially **learn better feature representations**, and use these to solve a task.

:::{style="padding-top: 15px;"}
:::

:::{.columns}
:::{.column width="13%"}
[_insufficient:_]{style="color: #C62828;"}
<br>
<br>
[_good:_]{style="color: #F57C00;"}
<br>
<br>
<br>
[_better:_]{style="color: #2E7D32;"}
:::

:::{.column width="5%"}
:::

:::{.column width="7%"}
data
<br>
<br>
data
<br>
<br>
<br>
data
:::

:::{.column width="5%"}
$\rightarrow$
<br>
<br>
$\rightarrow$
<br>
<br>
<br>
$\rightarrow$
:::

:::{.column width="20%"}
prediction
<br>
<br>
representation<br>
[_(e.g. crosscorr)_]{.color-text-muted}
<br>
<br>
representation
[_(e.g. crosscorr)_]{.color-text-muted}
:::

:::{.column width="5%"}
<br>
<br>
$\rightarrow$
<br>
<br>
<br>
$\rightarrow$
:::

:::{.column width="20%"}
<br>
<br>
prediction
<br>
<br>
<br>
representation
[_(e.g. crosscorr)_]{.color-text-muted}
:::

:::{.column width="5%"}
<br>
<br>
&nbsp;
<br>
<br>
$\rightarrow$
:::

:::{.column width="20%"}
<br>
<br>
&nbsp;
<br>
<br>
<br>
prediction
:::
:::

:::{style="padding-top: 10px;"}
:::

:::{.fragment}
Since neural networks are [_universal function approximators_]{.pink}, they can model arbitrarily complex relationships. The cost of doing so, is that we need a [lot of data]{.purple}.
:::



## Crosscorrelation

Crosscorrelation of two real-valued functions $f$ and $g$ is defined as

$$
(f \star g)(\tau) = \int_{-\infty}^{\infty} f(t)g(t + \tau)
$$

:::{.fragment}
For discrete signals the operation is computationally simple since $\int \rightarrow \sum$ and we just need to multiply and sum. 

:::{style="padding-top: 10px;"}
:::

![](https://upload.wikimedia.org/wikipedia/commons/7/71/Cross_correlation_animation.gif)
:::


## Crosscorrelation

![](figures/conv1d-0.png)

## Crosscorrelation

![](figures/conv1d-1.png)

## Crosscorrelation

![](figures/conv1d-2.png)

## Crosscorrelation

![](figures/conv1d-3.png)

## Crosscorrelation

![](figures/conv1d-4.png)

## Crosscorrelation

![](figures/conv1d-last.png)


## Crosscorrelation appreciation slide

:::{.absolute top="15%" left="20%" width="550px"}
![](figures/box-crosscorrelation.png){fig-align="center"style="margin-top: 0px;"}
:::

:::{.fragment .fade-out .rectangle .absolute top="40%" left="20%" width="650px" height="100px" style="background-color: #fff; border: 1px;"}
:::

:::{style="padding-top: 35%;"}
:::

:::{.fragment}
**Note:**  Time-reversing $f$ in the definition of crosscorrelation yields the [_**convolution**_]{.pink} operation.

In ML we got the terms mixed up and only talk about [_convolution_]{.pink}, even though we do crosscorrelation. 
:::


## Some more terminology

- **Layer:** A slice of the model where an internal representation is computed

:::{.columns style="text-align: center;"}
:::{.column width="5%"}
:::

:::{.column width="20%"}
data<br>([_input layer_]{.teal})
:::

:::{.column width="5%"}
$\rightarrow$
:::

:::{.column width="20%"}
representation<br>([*hidden layer 1*]{.orange})
:::

:::{.column width="5%"}
$\rightarrow$
:::

:::{.column width="20%"}
representation<br>([*hidden layer 2*]{.orange})
:::

:::{.column width="5%"}
$\rightarrow$
:::

:::{.column width="20%"}
prediction<br>([*output layer*]{.teal})
:::
:::

:::{style="padding-top: 10px;"}
:::

:::{.fragment}
- **Filter:** A template (sometimes also called a _kernel_)
:::

:::{.fragment}
- **Activation function:** Usually applied after each layer to introduce _non-linearity_ to the model 
:::

:::{.r-stack}

:::{.fragment .fade-in-then-out}
![](figures/sigmoid.png){width="400px"}

:::{.absolute top="70%" right="16%"}
Sigmoid
:::
:::

:::{.fragment .fade-in-then-out}
![](figures/tanh.png){width="400px"}

:::{.absolute top="70%" right="16%"}
tanh
:::
:::

:::{.fragment .fade-in-then-out}
![](figures/relu.png){width="400px"}

:::{.absolute top="70%" right="16%"}
ReLU
:::
:::

:::{.fragment .fade-in-then-out}
![](figures/gelu.png){width="400px"}

:::{.absolute top="70%" right="16%"}
GELU
:::
:::

:::{.fragment .fade-in-then-out}
![](figures/swish.png){width="400px"}

:::{.absolute top="70%" right="16%"}
Swish
:::
:::

:::{.fragment .fade-in-then-out}
![](figures/all-activations.png){width="400px"}
:::

:::


## Some deep learning frameworks 

::::{.r-stack}

:::{.absolute left="30%" top="20%" width="400px"}
[![](https://keras.io/img/logo.png)](https://keras.io/)
:::

:::{.absolute left="0%" bottom="20%" width="250px"}
[![](https://upload.wikimedia.org/wikipedia/commons/thumb/a/ab/TensorFlow_logo.svg/330px-TensorFlow_logo.svg.png)](https://www.tensorflow.org/)
:::

:::{.absolute left="30%" bottom="25%" width="150px"}
[![](https://upload.wikimedia.org/wikipedia/commons/thumb/8/86/Google_JAX_logo.svg/640px-Google_JAX_logo.svg.png)](https://jax.readthedocs.io/en/latest/)
:::

:::{.absolute left="55%" bottom="25%" width="250px"}
[![](https://upload.wikimedia.org/wikipedia/commons/9/96/Pytorch_logo.png)](https://pytorch.org/)
:::

:::{.absolute left="15%" bottom="0%" width="150px"}
[![](https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/Scikit_learn_logo_small.svg/640px-Scikit_learn_logo_small.svg.png)](https://scikit-learn.org/stable/)
:::

:::{.absolute left="45%" bottom="0%" width="170px"}
[![](https://upload.wikimedia.org/wikipedia/commons/thumb/3/31/NumPy_logo_2020.svg/640px-NumPy_logo_2020.svg.png)](https://numpy.org/doc/stable/)
:::


::::

:::{.absolute right="0%" top="25%"}
[High-level]{.blue} <br> _(optional)_
:::

:::{.absolute right="0%" bottom="30%"}
[Compute]{.blue} <br> _(choose one)_
:::

:::{.absolute right="0%" bottom="7%"}
[Supporting]{.blue} <br> _(useful)_
:::


## Interlude: Programming üë©üèº‚Äçüíª{.center background-color="#FBE9E7"}



## NumPy: _Numerical Python_

:::{.columns}
:::{.column width="60%"}
Most [_(all?)_]{.color-text-muted} scientific or data-driven Python projects rely on NumPy.

The different deep learning libraries implement the same concepts, so if we know NumPy, the transition to `<new flashy DL library‚ú®>` is easy.

:::{style="padding-top: 40px;"}
:::

:::{style="background-color: #E0F2F1; padding: 20px;" .img-shadow}
Core concept: [**Vectorisation**]{.teal}

Performing efficent operations on all data at once, without writing explicit loops
:::

:::
:::


:::{.absolute right="-5%" top="35%" width="370px"}
[![](https://upload.wikimedia.org/wikipedia/commons/thumb/3/31/NumPy_logo_2020.svg/640px-NumPy_logo_2020.svg.png)](https://numpy.org/doc/stable/)
:::



## {background-iframe="https://numpy.org/learn/" background-interactive="true" data-menu-title="Numpy docs"}

## NumPy arrays

At the core of NumPy is the `array`, which supports vectorised operations.

>_Example:_ Given a list of numbers, make a new list, where all the elements are multiplied by 2.

:::{.columns}

:::{.column width="50%"}

[Vanilla python:]{ style="margin-top=0px"}

```{.python}
>>> a = [1,2,3]; b = []
>>> for elem in a:
>>>   b.append(elem * 2)
b
[2, 4, 6]
```
:::

:::{.column width="50%"}
:::{.fragment}
Numpy:
```{.python code-line-numbers="1-5|3" }
>>> import numpy as np
>>> a = np.array([1,2,3])
>>> b = a * 2
>>> b
array([2 4 6])
```
:::
:::
:::

:::{.fragment}
Arrays can have any number of dimensions -- e.g. a 2D matrix is written
```{.python code-line-numbers="1|1,2-4|1,5-6"}
>>> a = np.array([[1,2,3],[4,5,6]])
>>> print(a)
[[1 2 3]
 [4 5 6]]
>>> a.shape
(2, 3)
```
:::


## NumPy arrays: Selecting data

In normal python, elements are _sliced_ from a list using `[start : stop]`:
```{.python code-line-numbers="false"}
>>> a = [0, 1, 2, 3, 4]
>>> a[2:4]                  # (remember zero-based indexing)
[2, 3]    
>>> a[:]                    # no start or stop -> select everything
[0, 1, 2, 3, 4]
```

:::{.fragment}
NumPy extends this to any number of dimensions, separated by "`,`":
```{.python code-line-numbers="false"}
>>> a = np.arange(1,10).reshape(3,3)
>>> a
array([[1, 2, 3],
       [4, 5, 6],
       [7, 8, 9]])
```
:::

:::{.columns}

:::{.column width="33%"}
:::{.fragment}
Select single element:
```{.python code-line-numbers="false"}
>>> a[1, 1]
5
```
:::
:::

:::{.column width="33%"}
:::{.fragment}
Select row:
```{.python code-line-numbers="false"}
>>> a[1, :]
array([4, 5, 6])
```
:::
:::

:::{.column width="33%"}
:::{.fragment}
Select column:
```{.python code-line-numbers="false"}
>>> a[:, 1]
array([2, 5, 8])
```
:::
:::

:::


## NumPy arrays: _Broadcasting_

Operations on arrays are typically done [element-by-element]{.color-teal}.

:::{.columns}
:::{.column width="50%"}
```{.python code-line-numbers="false"}
>>> a = np.array([1,2,3])
>>> np.power(a, 2)
array([1, 4, 9])
```
:::

:::{.column width="50%"}
:::{.fragment}
```{.python  code-line-numbers="false"}
>>> b = np.array([4,5,6])
>>> a * b
array([ 4, 10, 18])
```
:::
:::
:::

:::{.fragment}
In cases the shapes of two arrays don't match, numpy will try to [_make_]{.red} them match<br>(aka _broadcasting_):

```{.python code-line-numbers="1-3|1-6"}
# I type this
>>> a * 2
array([2, 4, 6])
# ...and numpy does this:
>>> a * np.array([2, 2, 2])
array([2, 4, 6])
```
:::

:::{.fragment}
![Numpy [docs](https://numpy.org/doc/stable/user/basics.broadcasting.html)](https://numpy.org/doc/stable/_images/broadcasting_1.png){width="40%" style="text-align: center;"}
:::


## Shapes

The number of time steps, channels, etc is described by the **shape** of the array:


:::{.r-stack}

![](figures/shapes1.png){width="80%"}

:::{.fragment}
![](figures/shapes2.png){width="80%"}
:::

:::



## Low-level TensorFlow

Usually we don't need to get involved with the underlying computational framework (in our case TensorFlow). But in case:

Most things work like NumPy, but with the benefit of GPU support and JIT compilation.

The core object is the [`Tensor`](https://www.tensorflow.org/api_docs/python/tf/Tensor), which is basically a multidimensional array.  

:::{.fragment}
NumPy

```{.python code-line-numbers="1,2|"}
>>> import numpy as np
>>> x = np.array([[1,2,3], [4,5,6]], dtype=np.float32)
>>> print(x)
[[1. 2. 3.]
 [4. 5. 6.]]

```
:::

:::{.fragment}
TensorFlow

```{.python code-line-numbers="1,2|"}
>>> import tensorflow as tf
>>> x = tf.constant([[1,2,3], [4,5,6]], dtype=tf.float32)
>>> print(x)
tf.Tensor(
[[1. 2. 3.]
 [4. 5. 6.]], shape=(2, 3), dtype=float32)
```
:::


## Building neural networks {.center background-color="#FCE4EC"}

<!-- :::{.absolute right="0%" top="0%" width="300px"} -->
[![](https://keras.io/img/logo.png){width="180px"}](https://keras.io/)
<!-- ::: -->





## My first convolutional network ü¶Ñ

Yesterday we pieced together a [**convnet**]{.color-indigo} using Keras' [sequential model API](https://keras.io/api/models/sequential/):


:::{style="padding-top:30px;"}
:::

```{.python code-line-numbers="|1|3|5,6|8,9|11|13|15|"}
model = keras.Sequential(
    [
        keras.Input(shape=(waveforms.shape[1], waveforms.shape[2])),
        
        keras.layers.Conv1D(filters=16, kernel_size=3, activation='relu'),
        keras.layers.MaxPooling1D(2),
        
        keras.layers.Conv1D(filters=16, kernel_size=3, activation='relu'),
        keras.layers.MaxPooling1D(2),
        
        keras.layers.Conv1D(filters=16, kernel_size=3, activation='relu'),
        
        keras.layers.GlobalMaxPooling1D(),
        
        keras.layers.Dense(1, activation='sigmoid')
    ]
)

```

## Pattern hierarchies

Remember the cat:

![](figures/chollet-cat.png){fig-align="center" width="60%"}



## More cats 


## Keras

The [Keras](https://keras.io/) framework contains all the high-level components we need to construct and train a neural network:

- `keras.layers`: Different types of layers and activation functions
- `keras.callbacks`: Monitor, modify or stop the training process
- `keras.optimizers`: Optimisation algorithms
- `keras.metrics`: Performance metrics
- `keras.losses`: Loss functions 
- `keras.datasets`: Small datasets for testing
- `keras.applications`: Pre-trained networks for different tasks

:::{.r-stack}

:::{.absolute bottom="0%" right="0%" width="200px"}
![](https://keras.io/img/logo.png)
:::

:::


## Exercise number 3 {.center background-color="#FBE9E7"}

:::{style="padding-top:30px;"}
:::

_Building a phase picker_

Open in [Colab](https://colab.research.google.com/github/smaeland/norsar-ml-workshop/blob/main/3_phase_picker.ipynb)
or [download](https://github.com/smaeland/norsar-ml-workshop/blob/main/3_phase_picker.ipynb)



## Post-exercise {.center background-color="#E0F2F1"}

_Great resource for illustrations and comparison of deep learning phase pickers:_

Myklebust, E. B., & K√∂hler, A. (2024). [Deep learning models for regional phase detection on seismic stations in Northern Europe and the European Arctic.](https://academic.oup.com/gji/article/239/2/862/7740467) Geophysical Journal International, 239(2), 862-881.


## Deep learning phase pickers

![PhaseNet](https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/gji/239/2/10.1093_gji_ggae298/1/ggae298fig2.jpeg?Expires=1761146227&Signature=iTeD13BpOnH-dGYwe6YjzUpMSRjEzYVyfMoxi3lYzC6TmLm920Eoug4GXNoEKoMajquirYiRJvSFso4R2XhfAc5cOe7r17RHrOUVNAJ-v~C6HJl4LlZmsR08X2e67I-Z9Kw-vExZmUSdXGXSiL1OltAdzuQ9AjkxNFApSsz7kMJhl9aCTF4DWaRY64GqfhsIwL01z4Jgq4Dtya8W08zur60XfWVa~kbTKGnVyfX6VwkUGwgxp8cSISTKFmwyhgxko3GsMrIHkVE7~0DaCjEHCUvydk7j1oyVPoqOBuiifo7DMEmqyIn-tvLH65eA1E0gVOliClWffCUDb42yS~UDrA__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA)


## Deep learning phase pickers

![EPick](https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/gji/239/2/10.1093_gji_ggae298/1/ggae298fig3.jpeg?Expires=1761199617&Signature=PFvP9NnMHCpTRHdsJ5pAfj27hd4jjHuOdntB4DHxhHEPVyzKXS04xc6NzVaz4pyz457Yi6IJNPSBE9s3s5A1E9gPOeTszNRCyrxs2Dgj1NssJ~vqA9s50ZDm5veBVkV1-DlmGm7q7KD~oWUHwtMEhxpiHYElEDeqTNhUOCfDdMO~HHSmMMyvLSqHuKqmXQruncWfFEqkGPnz-LaF72LsAEiXCKTx9w7eqW-1ksEPUTNi1-R5jvCFBpi-d9CZWW-UBX0hZ5FqO1ZiXWg5rJcN6h-gIUumbjicJkuAOltGRSS3z0C9aUw5NZ8revAjhXIg3UcKnStc8vqITtC31O5srQ__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA)

## Deep learning phase pickers

![EQTransformer](https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/gji/239/2/10.1093_gji_ggae298/1/ggae298fig4.jpeg?Expires=1761199619&Signature=rY6NTL9EYuYYA9AZpw2sZeZ6s2tZyV-BI~N7CFIWDHKhPK-Uv7Hx0HwMwOMv~dpnqivQNH948kK5QeljVVSExm7EQHgUhQH~yMxq7hGyrRcEjNa5tGQkEN~zBj8IZKZ-7fELhzzZZ0XYgsswxgv6NJENmNugEOBmOeiYCC3LtUygLL-OSEnY6gMP6f-0WHGGmA8KA7~awuB8Opj7-XVbMrJe6NHPZ-Y4t~caM0aNTVHJau2gnR~wl8fClsMahd0GbsqyO~luqkuZ0ViZE0BL2mmxQlGRpAHCscG~fL~n~aPlIi05BiMMO4DEyfvg1lCyvtY0rRBgOlyNoVxxRHU-LA__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA)

## Deep learning phase pickers

![TPhaseNet](https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/gji/239/2/10.1093_gji_ggae298/1/ggae298fig5.jpeg?Expires=1761199623&Signature=HN-RkR7TiasGfbnIwlEFKI0kCP0aIQzGMPQB3h63RbAH98ndUJ7v63VL~~H-Yu4GxndxiiiMa99WiOls0NC3MDXQL7uCuGhFiAVOl7uGm2sf37mB6r8pgYqmr8xetEtatFgCzQDYlb80-DKf5uTevbenIy5gG82EqUTD0SVbSC7S58Wz6jd5VhlkAiT72PtMVb9qYypQLZ8O4RaA-p0d423h2sbEypxYvVO5XVfoQtRqNytOLkmaN1fifD70kD6b-BKiK4Pjfczr-l66a~AeU9rRIQRRxfIRQiAi9Vh9JHtkWxJB-u5Iv-bZto3Xts~Rv-nORonx9Q6g2rX1DHglGQ__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA)


## {background-iframe="https://keras.io/guides/functional_api/" background-interactive="true" data-menu-title="Functional API"}


## Current and future ML at NORSAR {.center background-color="#E3F2FD"}

(Andreas K)


## Exercise number 4 {.center background-color="#FBE9E7"}

 

:::{style="padding-top:30px;"}
:::

_Using pretrained models_

Open in [Colab](https://colab.research.google.com/github/smaeland/norsar-ml-workshop/blob/main/4_clustering.ipynb)
or [download](https://github.com/smaeland/norsar-ml-workshop/blob/main/4_clustering.ipynb)



## Tips for doing ML when we have little training data 

:::{.fragment}
1. **Augmentation**

    Artificially expand the dataset by _e.g._ randomly adding noise

:::

:::{.fragment}
2. **Transfer learning**

    Train a model on a separate, larger dataset, then carefully re-train (_fine-tune_) it on the actual data

    Can re-use general patterns learnt in the bigger dataset, and then increase specificity to the actual task afterwards.

:::

:::{.fragment}
3. **Use pretrained models** (potentially with fine-tuning)

    Various models pretrained for seismic data available through [SeisBench](https://seisbench.readthedocs.io/en/stable/)

    Can also use pretrained models for entirely different tasks, if we reformat our data sufficiently (like in the exercise)
:::


## {background-iframe="https://seisbench.readthedocs.io/en/stable/"}



## Discussion {.center background-color="#E0F2F1"}

How will **you** use machine learning?

<!--------------------------------------------------------------------------------------------------->
