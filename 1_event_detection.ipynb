{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db8efff9-04a2-43d3-b49e-84ed3b3593a2",
   "metadata": {},
   "source": [
    "## 1: Event detection\n",
    "\n",
    "Before building a machine learning-based earthquake detector, let's try out two traditional methods for comparison: STA/LTA ratio, and crosscorrelation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc09124d-c0a3-427e-b498-2d139d0eb95d",
   "metadata": {},
   "source": [
    "First: Import the libraries that we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae32155-87a4-4f5d-b2e2-229baf58b4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0849a43-1f33-4c82-9796-dbcc041199f8",
   "metadata": {},
   "source": [
    "## Get the data file\n",
    "\n",
    "For this exercise we'll use a small set of sample events from the [STEAD](https://github.com/smousavi05/STEAD) dataset, which contains 60 s long waveforms at 100 Hz, for three components. In the sample file here, only the vertical component is present.\n",
    "\n",
    "The original dataset files come in a somewhat inconvenient format, so for this file (and the ones in the following exercises) they have been reformatted -- just so you know, in cases you later want to download all of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee56f9a-d2bf-4bc0-a212-ee66aaa5b63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://github.com/smaeland/norsar-ml-workshop/raw/refs/heads/main/sample_events_Zonly_TRAIN.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b415d5-0624-4873-8412-83f8d41a49d2",
   "metadata": {},
   "source": [
    "## Open the file and check the contents\n",
    "\n",
    "For performance reasons the file is in a binary format, which can't look at directly. But we can list the contents like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe209872-bdea-4d56-9c1e-5b78f9beda04",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'sample_events_Zonly_TRAIN.h5'\n",
    "fin = h5py.File(filename, 'r')\n",
    "print('Datasets in file:')\n",
    "print(fin.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a02ea21-821d-4092-913e-caf7fb49db9f",
   "metadata": {},
   "source": [
    "Now we can access each dataset and assign it to a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ab905e-405b-401b-805c-25b72fcbf9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveforms = fin.get('waveforms')[:]\n",
    "event_types = fin.get('type')[:]\n",
    "p_start = fin.get('p_start')[:]\n",
    "s_start = fin.get('s_start')[:]\n",
    "magnitude = fin.get('mag')[:]\n",
    "\n",
    "print(f'Waveforms data shape: {waveforms.shape}')\n",
    "print(f'-> {waveforms.shape[0]}Â events, {waveforms.shape[1]} data points per channel, {waveforms.shape[2]} channels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6a8403-463f-43ca-aa1f-7b055e5edfd6",
   "metadata": {},
   "source": [
    "Before we move on, we normalise the waveforms to unit amplitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619dfa4e-f5d9-4283-8255-ae48e35dc552",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vals = np.max(np.abs(waveforms), axis=1, keepdims=True)\n",
    "waveforms /= (max_vals + 1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbfd82b-c89f-46b8-b6ae-7026ff5e4bce",
   "metadata": {},
   "source": [
    "## Plot an event\n",
    "\n",
    "Let's plot the first event in the file. The file also contains the start positions for the P and S wave, if present. We'll add this as vertical lines on the plot.\n",
    "\n",
    "The code below is not super obvious unless you have experience with the Matplotlib library -- but that's not very important for the workshop. In case you want to change it, ChatGPT and friends are experts at these things.\n",
    "\n",
    "First some general settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161e21a4-2316-454a-930b-e06c483f453d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which event to look at (starts at 0)\n",
    "event_index = 1\n",
    "\n",
    "if event_index > len(waveforms):\n",
    "    raise RuntimeError(f'Event index {event_index} greater than number of events {len(waveforms)}')\n",
    "\n",
    "# Sampling rate\n",
    "sampling_rate = 100.0\n",
    "\n",
    "# Channel index (we have only one, so it's 0)\n",
    "channel_index = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c9d05a-d584-4edd-9e29-61c2ee0b0c69",
   "metadata": {},
   "source": [
    "Now for the plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f8dc63-b9af-4177-99b0-90d17993f945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get info for this event\n",
    "waveform = waveforms[event_index, :, channel_index]\n",
    "p_pick = p_start[event_index]\n",
    "s_pick = s_start[event_index]\n",
    "mag = magnitude[event_index]\n",
    "event_type = event_types[event_index]\n",
    "\n",
    "# Create the figure \n",
    "fig = plt.figure(figsize=(14, 4))\n",
    "\n",
    "# Create points along the x axis \n",
    "time_points = np.arange(len(waveform)) / sampling_rate\n",
    "\n",
    "# Plot\n",
    "plt.plot(time_points, waveform)\n",
    "\n",
    "if p_pick is not None:\n",
    "    p_arrival = plt.axvline(p_pick / sampling_rate, color='tab:orange', label='P arrival')\n",
    "if s_pick is not None:\n",
    "    s_arrival = plt.axvline(s_pick / sampling_rate, color='tab:red', label='S arrival')\n",
    "\n",
    "plt.ylabel('Z')\n",
    "    \n",
    "if p_pick is not None:\n",
    "    plt.legend(handles=[p_arrival, s_arrival], loc='upper right')\n",
    "\n",
    "title = f'Earthquake, mag {mag:.1f}' if event_type == 1 else 'Noise'\n",
    "plt.suptitle(title)\n",
    "\n",
    "plt.xlabel('Time [s]')\n",
    "\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e01dec-d51f-4435-aeab-69505d477df9",
   "metadata": {},
   "source": [
    "## First event detection method: STA/LTA\n",
    "\n",
    "We want to detect the event shown above, using the ratio of short-term average amplitude (STA) and long-term average (LTA). We can relatively easily compute this ourselves, but the useful [ObsPy](https://docs.obspy.org/index.html) library also provides it for us. The function is called `classis_sta_lta` and can be imported from the `signal.trigger` module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26fea0c-25cd-42fc-8864-ea2f99a219e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy.signal.trigger import classic_sta_lta\n",
    "\n",
    "# Create the plot, with two panels this time\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, sharex=True, figsize=(14, 6))\n",
    "fig.subplots_adjust(hspace=0)\n",
    "\n",
    "time_points = np.arange(len(waveform)) / sampling_rate\n",
    "\n",
    "# Compute the ratio\n",
    "sta_lta = classic_sta_lta(waveform, int(0.5*sampling_rate), int(5.0*sampling_rate))\n",
    "\n",
    "# Plot data with STA/LTA ratio below\n",
    "axes[0].plot(time_points, waveform)\n",
    "axes[1].plot(time_points, sta_lta)\n",
    "\n",
    "axes[0].set_ylabel('Z')\n",
    "axes[1].set_ylabel('STA/LTA ratio')\n",
    "axes[1].set_xlabel('Time [s]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e14d97e-8998-4716-918f-f8fc72606790",
   "metadata": {},
   "source": [
    "Looks good! If we now put a threshold on the STA/LTA ratio, we have an event detector.\n",
    "\n",
    "### Optional exercise 1:\n",
    "\n",
    "Implement such a threshold, and add a line to the plot showing detections. Something like `np.where(sta_lta > threshold)` can prove useful.\n",
    "\n",
    "### Optional exercise 2:\n",
    "\n",
    "Replace the `classic_sta_lta` function with other methods shown in the ObsPy [trigger tutorial](https://docs.obspy.org/tutorial/code_snippets/trigger_tutorial.html), for instance `recursive_sta_lta` or `z_detect`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc50e7d-0115-4603-b8bb-f8a55618d2f9",
   "metadata": {},
   "source": [
    "## Second method: Template cross-correlation\n",
    "\n",
    "For the next test, let's use the first event we plotted as a template, and cross-correlate it with other potential events.\n",
    "\n",
    "Again, ObsPy has a conventient function for us to use: `correlate_template`. We can write a new function around it that allows for some quick experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befe8c9f-6685-49d3-be30-b5b28387fc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy.signal.cross_correlation import correlate_template\n",
    "\n",
    "def plot_correlation(event_index, template_index):\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=1, sharex=True, figsize=(14, 6))\n",
    "    fig.subplots_adjust(hspace=0)\n",
    "\n",
    "    # Get the event and template waveforms\n",
    "    waveform = waveforms[event_index, :, channel_index]\n",
    "    template = waveforms[template_index, :, channel_index]\n",
    "\n",
    "    time_points = np.arange(len(waveform)) / sampling_rate\n",
    "\n",
    "    # Check that the template contains picks (i.e. is not noise)\n",
    "    # If you like, you can add random numbers here instead, to be able to use noise events too.\n",
    "    template_p_start = p_start[template_index]\n",
    "    template_s_start = s_start[template_index]\n",
    "\n",
    "    if template_p_start < 0 or template_s_start < 0:\n",
    "        raise RuntimeError('Template waveform is a noise event') \n",
    "    \n",
    "    # We'll cut it down to start 1 s before the P arrival, and stop 10 s after the S arrival.\n",
    "    template_start_sample = int(template_p_start - 1*sampling_rate)\n",
    "    template_end_sample = int(template_s_start + 10*sampling_rate)\n",
    "    template = template[template_start_sample : template_end_sample]\n",
    "    \n",
    "    # Compute the cross-correlation, and find the position of max correlation\n",
    "    corr = correlate_template(waveform, template, mode='same')\n",
    "    max_corr_index = np.argmax(corr) - len(template)//2\n",
    "    max_corr_time_points = (np.arange(len(template)) + max_corr_index) / sampling_rate\n",
    "    \n",
    "    print('waveform.shape:', waveform.shape)\n",
    "    print('template.shape:', template.shape)\n",
    "    print('corr.shape:', corr.shape)\n",
    "    \n",
    "    axes[0].plot(time_points, waveform)\n",
    "    axes[1].plot(time_points, corr)\n",
    "    axes[2].plot(time_points, waveform / np.max(waveform), alpha=0.7)\n",
    "    axes[2].plot(max_corr_time_points, template / np.max(template), color='tab:orange', label='Template')\n",
    "\n",
    "    axes[0].set_ylabel('Z')\n",
    "    axes[1].set_ylabel('Correlation')\n",
    "    axes[1].set_ylim(-1.05, 1.05)\n",
    "    axes[2].set_ylabel('Best match')\n",
    "    axes[2].legend(loc='upper right')\n",
    "        \n",
    "    axes[1].set_xlabel('Time [s]')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4860973d-6a76-416c-ac43-9a78e854184b",
   "metadata": {},
   "source": [
    "Let's try it out.\n",
    "\n",
    "First, correlating a waveform against itself (it should hopefully be able to detect itself):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2d229c-e225-4157-94cf-7ac80e89324e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation(event_index=1, template_index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1970cbf1-7106-41ad-a884-736e39773455",
   "metadata": {},
   "source": [
    "Now we can try it agaist noise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c06075a-655c-4e6b-94dd-263906539c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation(event_index=0, template_index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bf029b-2b5c-4944-8208-892e7709f933",
   "metadata": {},
   "source": [
    "Or agaist a different event:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465fcabc-4d0a-4e66-9b7f-d55e2718d9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation(event_index=2, template_index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b6fc62-afd7-474f-bfdc-a2e5dd91dd98",
   "metadata": {},
   "source": [
    "### Exercise: \n",
    "\n",
    "Edit the event and template indices to evaluate our detection capabilities on different events."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb93c92-24f5-494f-8d64-8abef81ef5b8",
   "metadata": {},
   "source": [
    "## Third event detection method: Machine learning-based model\n",
    "\n",
    "Last piece of our comparison is of course to add a ML-based model. For now we'll just use it, but in the following exercises we'll also train our own an try to improve on it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45646cd-77ca-4a11-b1c7-69832cb139a8",
   "metadata": {},
   "source": [
    "First, get the model file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f98694-35f7-4952-a209-f7fb262ccbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://github.com/smaeland/norsar-ml-workshop/raw/refs/heads/dev/phase_picker.keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb20c91-ca2c-48da-9c60-42ad3831c6b1",
   "metadata": {},
   "source": [
    "Then, import the required library, and load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d101a5f7-019f-403e-9c44-21b5a04fd23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model('phase_picker.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60494271-7512-4f24-b644-e2613a460441",
   "metadata": {},
   "source": [
    "Just as a peek on the stuff we'll do later, we can print the model structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa59a7c-4712-4ab1-a781-868200648c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d48040-e52e-4169-8065-c0226c4bdbea",
   "metadata": {},
   "source": [
    "Now we're ready to run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e8da89-8a89-4494-b9ef-7d691d5a2db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_detect(event_index):\n",
    "\n",
    "    waveform = waveforms[event_index, :, :]\n",
    "    waveform = np.expand_dims(waveform, axis=0)\n",
    "    #waveform = np.expand_dims(waveform, axis=2)\n",
    "\n",
    "    print('waveform.shape:', waveform.shape)\n",
    "    \n",
    "    predictions = model(waveform)\n",
    "\n",
    "    print('predictions.shape:', predictions.shape)\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=2, ncols=1, sharex=True, figsize=(14, 6))\n",
    "    fig.subplots_adjust(hspace=0)\n",
    "\n",
    "    time_points = np.arange(waveform.shape[1]) / sampling_rate\n",
    "\n",
    "    axes[0].plot(time_points, waveform[0, :, 0])\n",
    "    axes[1].plot(time_points, predictions[0, :, 0], label='P similarity')\n",
    "    axes[1].plot(time_points, predictions[0, :, 1], label='S similarity')\n",
    "    axes[1].legend(loc='upper right')\n",
    "        \n",
    "    axes[0].set_ylabel('Z')\n",
    "    axes[1].set_ylim(0, 1)\n",
    "    axes[1].set_ylabel('ML prediction')\n",
    "    axes[1].set_xlabel('Time [s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651a3ad1-4b4e-4f7d-a960-524b146fff1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_detect(event_index=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6081b12b-d09c-44d1-aaee-2e3cbefa5938",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Our model is a small one, based on a miniaturised version of the [PhaseNet](https://academic.oup.com/gji/article/216/1/261/5129142) model. Its main purpose in this case is to run fast even without a GPU, and it's likely prone to making errors. Try different event numbers to see where it works and where it makes mistakes. \n",
    "\n",
    "This model is the one to beat when we start training our own in the next exer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
